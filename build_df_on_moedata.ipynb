{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5_n1anBIzok7",
        "Jeuu32a90beW",
        "gFK9C8-_tSK1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setting"
      ],
      "metadata": {
        "id": "5_n1anBIzok7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pickle\n",
        "import sys\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "\n",
        "path = 'your_path'\n",
        "os.chdir(path)"
      ],
      "metadata": {
        "id": "scCGVZay1fLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencc"
      ],
      "metadata": {
        "id": "WrdJeY7NzmpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get 萌典 moe-dict\n",
        "\n",
        "- https://github.com/g0v/moedict-data.git\n",
        "- https://github.com/g0v/moedict-epub.git"
      ],
      "metadata": {
        "id": "xwSlam290ppI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!sudo apt install -y python g++ make nodejs python-lxml curl npm"
      ],
      "metadata": {
        "id": "rPHQ1XP-3tfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm i\n",
        "!pip install lxml\n",
        "!sudo npm i -g gulp"
      ],
      "metadata": {
        "id": "09yapvM23y80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth 1 https://github.com/g0v/moedict-data.git\n",
        "!git clone --depth 1 https://github.com/g0v/moedict-epub.git\n",
        "!cp -v moedict-data/dict-revised.json moedict-epub/\n",
        "!cd moedict-epub"
      ],
      "metadata": {
        "id": "2yEJCuqV1-yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build my DataFrame"
      ],
      "metadata": {
        "id": "149fBh6MnW0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "沒有採用的資料：\"non_radical_stroke_count\", \"radical\", \"stroke_count\""
      ],
      "metadata": {
        "id": "VOGBs4VOSusC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# read json\n",
        "with open(path+'/moedict-data/dict-revised.json', \"r\") as read_file:\n",
        "    data = json.load(read_file)\n",
        "print(type(data),len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wQNmbVD2jzn",
        "outputId": "9448e942-65be-41f6-8d9f-a4518f1495c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 163087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# function to extract information from each dictionary and create a list of dictionaries\n",
        "def extract_info(d):\n",
        "    title = d['title']\n",
        "    rows = []\n",
        "    for heteronym in d['heteronyms']:\n",
        "    # INFO in the 2nd layer \n",
        "        if 'bopomofo' in heteronym:\n",
        "            bopomofo = heteronym['bopomofo']\n",
        "        else:\n",
        "            bopomofo = ''\n",
        "        if 'pinyin' in heteronym:\n",
        "            pinyin = heteronym['pinyin']\n",
        "        else:\n",
        "            pinyin = ''\n",
        "            \n",
        "        for i, definition in enumerate(heteronym['definitions']):\n",
        "        # INFO in the 3rd layer (iterrating each senses of this lemma)\n",
        "            lemma_text = title\n",
        "            sense_idx = i+1\n",
        "            definition_text = definition['def']\n",
        "            \n",
        "            pos = definition.get('type', '')\n",
        "\n",
        "            if 'quote' in definition:\n",
        "                quote = definition['quote'][0]\n",
        "            else:\n",
        "                quote = ''\n",
        "            if 'example' in definition:\n",
        "                examples = [s[s.index('「')+1:s.index('」')] for s in definition['example']]\n",
        "            else:\n",
        "                examples = ''\n",
        "            \n",
        "            if 'anotonyms' in definition:\n",
        "                anotonyms = definition['anotonyms'].split(',')\n",
        "            else:\n",
        "                anotonyms = []\n",
        "            if 'synonyms' in definition:\n",
        "                synonyms = definition['synonyms'].split(',')\n",
        "            else:\n",
        "                synonyms = []      \n",
        "\n",
        "            row_dict = {'lemma_text': lemma_text,\n",
        "                        'sense_idx': sense_idx,\n",
        "                        'definition': definition_text,\n",
        "                        'synonyms': synonyms,\n",
        "                        'anotonyms': anotonyms,\n",
        "                        'quote': quote,\n",
        "                        'examples': examples,\n",
        "                        'POS': pos,\n",
        "                        'bopomofo': bopomofo,\n",
        "                        'pinyin': pinyin}\n",
        "            rows.append(row_dict)\n",
        "    return rows"
      ],
      "metadata": {
        "id": "zi2oLPxVmDE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract information from the list of dictionaries\n",
        "rows = []\n",
        "for d in data:\n",
        "    rows += extract_info(d)\n",
        "\n",
        "# Create a pandas DataFrame from the list of dictionaries\n",
        "df = pd.DataFrame(rows, columns=['lemma_text','sense_idx','definition', 'synonyms', 'anotonyms', \n",
        "                                    'quote', 'examples','POS','bopomofo','pinyin'])\n",
        "\n",
        "print(len(df))"
      ],
      "metadata": {
        "id": "zmPjuCCsmHIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine quotes & examples into []\n",
        "# only examples -> [examples], only quotes -> [quote]\n",
        "\n",
        "def merge_quotes_and_examples(row):\n",
        "    quote = row['quote']\n",
        "    examples = row['examples']\n",
        "    if not quote and not examples:\n",
        "        return []\n",
        "    elif quote and examples:\n",
        "        if type(quote) == str:\n",
        "            quote = [quote]\n",
        "        result = []\n",
        "        result+=examples\n",
        "        result+=quote\n",
        "        return result\n",
        "    elif examples:\n",
        "        return examples\n",
        "    else:\n",
        "        if type(quote) == str:\n",
        "            quote = [quote]\n",
        "            return quote\n",
        "\n",
        "# apply the function to each row of the DataFrame\n",
        "df['examples_quote'] = df.apply(merge_quotes_and_examples, axis=1)\n",
        "\n",
        "# drop the original quote and examples columns\n",
        "df.drop(columns=['quote', 'examples'], inplace=True)\n",
        "\n",
        "print(len(df))"
      ],
      "metadata": {
        "id": "trzMdsAKmLTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "optional\n",
        "'''\n",
        "\n",
        "# find rows whose lemma_text contains {} \\d a-zA-Z\n",
        "index = df[df['lemma_text'].str.contains(r'[\\{\\}\\da-zA-Z]')].index\n",
        "len(index)\n",
        "\n",
        "# drop the rows by their idxs\n",
        "df.drop(index, inplace=True)\n",
        "print(len(df))"
      ],
      "metadata": {
        "id": "qgQLo5WqmVUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # save to csv\n",
        "df.to_csv('moe_flat.csv', encoding='utf-8',index=False)"
      ],
      "metadata": {
        "id": "eCiBpJM_mRVf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}